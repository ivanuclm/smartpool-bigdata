{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0af9725-4451-4cc4-a1b0-1960a6304176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-379c133f-8b19-4dc4-a8cb-31d7a0d77025;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 119ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-379c133f-8b19-4dc4-a8cb-31d7a0d77025\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "26/01/25 22:41:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark OK: 4.0.1\n",
      "BASE: s3a://spark/medallion\n",
      "BRONZE: s3a://spark/medallion/bronze\n",
      "SILVER: s3a://spark/medallion/silver\n",
      "GOLD: s3a://spark/medallion/gold\n",
      "STATE: s3a://spark/medallion/_state\n",
      "JDBC: jdbc:sqlserver://sqlserver:1433;databaseName=smartpool;encrypt=true;trustServerCertificate=true;\n"
     ]
    }
   ],
   "source": [
    "from smartpool_config import *\n",
    "\n",
    "spark = create_spark(\"smartpool-gold-electricity\")\n",
    "\n",
    "print(\"Spark OK:\", spark.version)\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"BRONZE:\", BRONZE)\n",
    "print(\"SILVER:\", SILVER)\n",
    "print(\"GOLD:\", GOLD)\n",
    "print(\"STATE:\", STATE)\n",
    "print(\"JDBC:\", JDBC_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17e7c0d-4c2e-4902-b221-19135e3c931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/25 22:41:13 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "26/01/25 22:41:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver pools : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver events: 16\n",
      "Silver elec  : 720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[ts_utc: string, hour: int, price_eur_mwh: double, price_eur_kwh: double, region: string, source: string, source_file: string, ingest_ts: timestamp, ingest_date: date, date: date, silver_ingest_ts: timestamp]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[pool_id: int, id: int, event_time: timestamp, intervention_type: string, product_type: string, product_amount: double, notes: string, updated_at: timestamp, event_date: date]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SILVER\n",
    "SILVER_POOLS   = f\"{SILVER}/pools_dim\"\n",
    "SILVER_EVENTS  = f\"{SILVER}/maintenance_events\"\n",
    "SILVER_ELEC    = f\"{SILVER}/electricity_prices\"\n",
    "\n",
    "# GOLD\n",
    "GOLD_ELEC_DAILY = f\"{GOLD}/electricity_daily_stats\"\n",
    "GOLD_ELEC_PEAK  = f\"{GOLD}/electricity_peak_hours\"\n",
    "GOLD_EVENTS_ENR = f\"{GOLD}/maintenance_events_enriched\"\n",
    "GOLD_EVENTS_COST= f\"{GOLD}/maintenance_events_cost\"\n",
    "\n",
    "pools_s  = spark.read.format(\"delta\").load(SILVER_POOLS)\n",
    "events_s = spark.read.format(\"delta\").load(SILVER_EVENTS)\n",
    "elec_s   = spark.read.format(\"delta\").load(SILVER_ELEC)\n",
    "\n",
    "print(\"Silver pools :\", pools_s.count())\n",
    "print(\"Silver events:\", events_s.count())\n",
    "print(\"Silver elec  :\", elec_s.count())\n",
    "\n",
    "display(elec_s.orderBy(F.col(\"date\").desc(), F.col(\"hour\").asc()).limit(10))\n",
    "display(events_s.orderBy(F.col(\"event_time\").desc()).limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7c09dd-0acd-48be-8830-ee68839ba998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD electricity_daily_stats OK -> s3a://spark/medallion/gold/electricity_daily_stats rows: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[date: date, region: string, avg_price_eur_kwh: double, min_price_eur_kwh: double, max_price_eur_kwh: double, avg_price_eur_mwh: double, min_price_eur_mwh: double, max_price_eur_mwh: double, rows: bigint, gold_calc_ts: timestamp]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gold_elec_daily = (elec_s\n",
    "    .groupBy(\"date\", \"region\")\n",
    "    .agg(\n",
    "        F.avg(\"price_eur_kwh\").alias(\"avg_price_eur_kwh\"),\n",
    "        F.min(\"price_eur_kwh\").alias(\"min_price_eur_kwh\"),\n",
    "        F.max(\"price_eur_kwh\").alias(\"max_price_eur_kwh\"),\n",
    "        F.avg(\"price_eur_mwh\").alias(\"avg_price_eur_mwh\"),\n",
    "        F.min(\"price_eur_mwh\").alias(\"min_price_eur_mwh\"),\n",
    "        F.max(\"price_eur_mwh\").alias(\"max_price_eur_mwh\"),\n",
    "        F.count(\"*\").alias(\"rows\")\n",
    "    )\n",
    "    .withColumn(\"gold_calc_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "(gold_elec_daily.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"date\")\n",
    "    .save(GOLD_ELEC_DAILY)\n",
    ")\n",
    "\n",
    "print(\"GOLD electricity_daily_stats OK ->\", GOLD_ELEC_DAILY, \"rows:\", gold_elec_daily.count())\n",
    "display(gold_elec_daily.orderBy(F.col(\"date\").desc(), F.col(\"region\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7102647b-067e-4293-ab64-b946377962e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD electricity_peak_hours OK -> s3a://spark/medallion/gold/electricity_peak_hours rows: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[date: date, region: string, hour: int, price_eur_kwh: double, price_eur_mwh: double, rank: int, gold_calc_ts: timestamp]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOP_N = 5\n",
    "\n",
    "w = Window.partitionBy(\"date\", \"region\").orderBy(F.col(\"price_eur_kwh\").desc(), F.col(\"hour\").asc())\n",
    "\n",
    "gold_peak = (elec_s\n",
    "    .select(\"date\", \"region\", \"hour\", \"price_eur_kwh\", \"price_eur_mwh\")\n",
    "    .withColumn(\"rank\", F.row_number().over(w))\n",
    "    .filter(F.col(\"rank\") <= F.lit(TOP_N))\n",
    "    .withColumn(\"gold_calc_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "(gold_peak.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"date\")\n",
    "    .save(GOLD_ELEC_PEAK)\n",
    ")\n",
    "\n",
    "print(\"GOLD electricity_peak_hours OK ->\", GOLD_ELEC_PEAK, \"rows:\", gold_peak.count())\n",
    "display(gold_peak.orderBy(F.col(\"date\").desc(), F.col(\"region\"), F.col(\"rank\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2600a6db-67e9-4103-891d-2385feab2907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD maintenance_events_enriched OK -> s3a://spark/medallion/gold/maintenance_events_enriched rows: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[pool_id: int, event_date: date, event_hour: int, region: string, id: int, event_time: timestamp, intervention_type: string, product_type: string, product_amount: double, notes: string, updated_at: timestamp, price_eur_kwh: double, price_eur_mwh: double, pool_name: string, location: string, volume_liters: int, is_heated: boolean, owner_type: string, gold_calc_ts: timestamp]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepara events con date/hour\n",
    "events_enrich_base = (events_s\n",
    "    .withColumn(\"event_date\", F.to_date(\"event_time\"))\n",
    "    .withColumn(\"event_hour\", F.hour(\"event_time\"))\n",
    ")\n",
    "\n",
    "# Prepara elec (keys de join)\n",
    "elec_key = (elec_s\n",
    "    .select(\n",
    "        F.col(\"date\").alias(\"event_date\"),\n",
    "        F.col(\"hour\").alias(\"event_hour\"),\n",
    "        \"region\",\n",
    "        \"price_eur_kwh\",\n",
    "        \"price_eur_mwh\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Como solo tenemos ESPAÑA, con esto basta. Si en el futuro hay más regiones, derivariamos por location.\n",
    "DEFAULT_REGION = \"ES\"\n",
    "\n",
    "gold_events_enriched = (events_enrich_base\n",
    "    .withColumn(\"region\", F.lit(DEFAULT_REGION))\n",
    "    .join(elec_key, on=[\"event_date\", \"event_hour\", \"region\"], how=\"left\")\n",
    "    .join(pools_s.select(\"pool_id\",\"pool_name\",\"location\",\"volume_liters\",\"is_heated\",\"owner_type\"), on=\"pool_id\", how=\"left\")\n",
    "    .withColumn(\"gold_calc_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "(gold_events_enriched.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .save(GOLD_EVENTS_ENR)\n",
    ")\n",
    "\n",
    "print(\"GOLD maintenance_events_enriched OK ->\", GOLD_EVENTS_ENR, \"rows:\", gold_events_enriched.count())\n",
    "display(gold_events_enriched.orderBy(F.col(\"event_time\").desc()).limit(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99488bca-30e3-42ee-9b10-4288da9d76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD maintenance_events_cost OK -> s3a://spark/medallion/gold/maintenance_events_cost rows: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[pool_id: int, event_date: date, event_hour: int, region: string, id: int, event_time: timestamp, intervention_type: string, product_type: string, product_amount: double, notes: string, updated_at: timestamp, price_eur_kwh: double, price_eur_mwh: double, pool_name: string, location: string, volume_liters: int, is_heated: boolean, owner_type: string, gold_calc_ts: timestamp, estimated_energy_kwh: double, estimated_cost_eur: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Consumo (kWh) por tipo de intervención\n",
    "energy_map = F.create_map(\n",
    "    F.lit(\"filter_backwash\"), F.lit(1.2),\n",
    "    F.lit(\"refill\"),          F.lit(0.8),\n",
    "    F.lit(\"chlorine\"),        F.lit(0.0),\n",
    "    F.lit(\"ph_correction\"),   F.lit(0.0),\n",
    ")\n",
    "\n",
    "gold_events_cost = (gold_events_enriched\n",
    "    .withColumn(\"estimated_energy_kwh\", energy_map[F.col(\"intervention_type\")])\n",
    "    .withColumn(\"estimated_cost_eur\", F.col(\"estimated_energy_kwh\") * F.col(\"price_eur_kwh\"))\n",
    "    .withColumn(\"estimated_cost_eur\", F.round(F.col(\"estimated_cost_eur\"), 4))\n",
    ")\n",
    "\n",
    "(gold_events_cost.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .save(GOLD_EVENTS_COST)\n",
    ")\n",
    "\n",
    "print(\"GOLD maintenance_events_cost OK ->\", GOLD_EVENTS_COST, \"rows:\", gold_events_cost.count())\n",
    "display(gold_events_cost.orderBy(F.col(\"event_time\").desc()).limit(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b268232-8fc2-41a4-9d04-355360d6705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD daily rows: 30\n",
      "GOLD peak  rows: 150\n",
      "GOLD enr   rows: 16\n",
      "GOLD cost  rows: 16\n",
      "+----------+------+----+\n",
      "|date      |region|rows|\n",
      "+----------+------+----+\n",
      "|2026-02-13|ES    |5   |\n",
      "|2026-02-12|ES    |5   |\n",
      "|2026-02-11|ES    |5   |\n",
      "|2026-02-10|ES    |5   |\n",
      "|2026-02-09|ES    |5   |\n",
      "|2026-02-08|ES    |5   |\n",
      "|2026-02-07|ES    |5   |\n",
      "|2026-02-06|ES    |5   |\n",
      "|2026-02-05|ES    |5   |\n",
      "|2026-02-04|ES    |5   |\n",
      "|2026-02-03|ES    |5   |\n",
      "|2026-02-02|ES    |5   |\n",
      "|2026-02-01|ES    |5   |\n",
      "|2026-01-31|ES    |5   |\n",
      "|2026-01-30|ES    |5   |\n",
      "|2026-01-29|ES    |5   |\n",
      "|2026-01-28|ES    |5   |\n",
      "|2026-01-27|ES    |5   |\n",
      "|2026-01-26|ES    |5   |\n",
      "|2026-01-25|ES    |5   |\n",
      "+----------+------+----+\n",
      "only showing top 20 rows\n",
      "+----+------------------+\n",
      "|rows|rows_without_price|\n",
      "+----+------------------+\n",
      "|16  |0                 |\n",
      "+----+------------------+\n",
      "\n",
      "+-------+-------------------------------+----------+----------------+--------------------+\n",
      "|pool_id|pool_name                      |num_events|sum_est_cost_eur|avg_est_cost_eur    |\n",
      "+-------+-------------------------------+----------+----------------+--------------------+\n",
      "|5      |Piscina Polideportivo Municipal|3         |0.1151          |0.03836666666666667 |\n",
      "|1      |Piscina Casa Pueblo            |5         |0.1151          |0.02302             |\n",
      "|3      |Piscina Airbnb Rural           |2         |0.1133          |0.05665             |\n",
      "|4      |Piscina Hotel Centro           |3         |0.0773          |0.025766666666666663|\n",
      "|2      |Piscina Villa Mila             |3         |0.0734          |0.024466666666666668|\n",
      "+-------+-------------------------------+----------+----------------+--------------------+\n",
      "\n",
      "QA FINAL OK\n"
     ]
    }
   ],
   "source": [
    "g_daily = spark.read.format(\"delta\").load(GOLD_ELEC_DAILY)\n",
    "g_peak  = spark.read.format(\"delta\").load(GOLD_ELEC_PEAK)\n",
    "g_enr   = spark.read.format(\"delta\").load(GOLD_EVENTS_ENR)\n",
    "g_cost  = spark.read.format(\"delta\").load(GOLD_EVENTS_COST)\n",
    "\n",
    "print(\"GOLD daily rows:\", g_daily.count())\n",
    "print(\"GOLD peak  rows:\", g_peak.count())\n",
    "print(\"GOLD enr   rows:\", g_enr.count())\n",
    "print(\"GOLD cost  rows:\", g_cost.count())\n",
    "\n",
    "# Check: peaks = TOP_N por date y region (si hay datos completos)\n",
    "g_peak.groupBy(\"date\",\"region\").agg(F.count(\"*\").alias(\"rows\")).orderBy(F.col(\"date\").desc()).show(20, truncate=False)\n",
    "\n",
    "# Check: enriched debería tener price_eur_kwh no nulo salvo que falte ese día/hora\n",
    "g_enr.select(\n",
    "    F.count(\"*\").alias(\"rows\"),\n",
    "    F.sum(F.when(F.col(\"price_eur_kwh\").isNull(), 1).otherwise(0)).alias(\"rows_without_price\")\n",
    ").show(truncate=False)\n",
    "\n",
    "# Métrica vistosa: coste estimado por piscina\n",
    "(g_cost.groupBy(\"pool_id\", \"pool_name\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_events\"),\n",
    "        F.sum(\"estimated_cost_eur\").alias(\"sum_est_cost_eur\"),\n",
    "        F.avg(\"estimated_cost_eur\").alias(\"avg_est_cost_eur\")\n",
    "    )\n",
    "    .orderBy(F.col(\"sum_est_cost_eur\").desc())\n",
    ").show(20, truncate=False)\n",
    "\n",
    "print(\"QA FINAL OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19119eea-6e0b-4eff-b475-4abbfc186186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+-----------------+\n",
      "|event_date|events|events_without_price|events_with_price|\n",
      "+----------+------+--------------------+-----------------+\n",
      "|2026-01-25|2     |0                   |2                |\n",
      "|2026-01-24|2     |0                   |2                |\n",
      "|2026-01-23|2     |0                   |2                |\n",
      "|2026-01-22|2     |0                   |2                |\n",
      "|2026-01-21|1     |0                   |1                |\n",
      "|2026-01-20|1     |0                   |1                |\n",
      "|2026-01-19|1     |0                   |1                |\n",
      "|2026-01-18|2     |0                   |2                |\n",
      "|2026-01-17|1     |0                   |1                |\n",
      "|2026-01-16|1     |0                   |1                |\n",
      "|2026-01-15|1     |0                   |1                |\n",
      "+----------+------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(g_enr\n",
    "  .groupBy(\"event_date\")\n",
    "  .agg(\n",
    "      F.count(\"*\").alias(\"events\"),\n",
    "      F.sum(F.when(F.col(\"price_eur_kwh\").isNull(), 1).otherwise(0)).alias(\"events_without_price\"),\n",
    "      (F.count(\"*\") - F.sum(F.when(F.col(\"price_eur_kwh\").isNull(), 1).otherwise(0))).alias(\"events_with_price\")\n",
    "  )\n",
    "  .orderBy(F.col(\"event_date\").desc())\n",
    ").show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6999dfb2-1426-4a2d-9aeb-5023f56acf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
