{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0af9725-4451-4cc4-a1b0-1960a6304176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6435f54f-1f84-4579-bad1-4175e91d1be6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.13/4.0.0/delta-spark_2.13-4.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-spark_2.13;4.0.0!delta-spark_2.13.jar (7060ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/4.0.0/delta-storage-4.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;4.0.0!delta-storage.jar (443ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.13.1/antlr4-runtime-4.13.1.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.13.1!antlr4-runtime.jar (747ms)\n",
      ":: resolution report :: resolve 4508ms :: artifacts dl 8253ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6435f54f-1f84-4579-bad1-4175e91d1be6\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 0 already retrieved (7933kB/9ms)\n",
      "26/01/25 20:46:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark OK: 4.0.1\n",
      "BASE: s3a://spark/medallion\n",
      "BRONZE: s3a://spark/medallion/bronze\n",
      "SILVER: s3a://spark/medallion/silver\n",
      "GOLD: s3a://spark/medallion/gold\n",
      "STATE: s3a://spark/medallion/_state\n",
      "JDBC: jdbc:sqlserver://sqlserver:1433;databaseName=smartpool;encrypt=true;trustServerCertificate=true;\n"
     ]
    }
   ],
   "source": [
    "from smartpool_config import *\n",
    "\n",
    "spark = create_spark(\"smartpool-gold\")\n",
    "\n",
    "print(\"Spark OK:\", spark.version)\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"BRONZE:\", BRONZE)\n",
    "print(\"SILVER:\", SILVER)\n",
    "print(\"GOLD:\", GOLD)\n",
    "print(\"STATE:\", STATE)\n",
    "print(\"JDBC:\", JDBC_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17e7c0d-4c2e-4902-b221-19135e3c931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POOLS_SILVER: s3a://spark/medallion/silver/pools_dim\n",
      "EVENTS_SILVER: s3a://spark/medallion/silver/maintenance_events\n",
      "GOLD_DAILY: s3a://spark/medallion/gold/pool_daily_metrics\n",
      "GOLD_LATEST: s3a://spark/medallion/gold/pool_latest_event\n"
     ]
    }
   ],
   "source": [
    "POOLS_SILVER  = f\"{SILVER}/pools_dim\"\n",
    "EVENTS_SILVER = f\"{SILVER}/maintenance_events\"\n",
    "\n",
    "GOLD_DAILY    = f\"{GOLD}/pool_daily_metrics\"\n",
    "GOLD_LATEST   = f\"{GOLD}/pool_latest_event\"\n",
    "\n",
    "print(\"POOLS_SILVER:\", POOLS_SILVER)\n",
    "print(\"EVENTS_SILVER:\", EVENTS_SILVER)\n",
    "print(\"GOLD_DAILY:\", GOLD_DAILY)\n",
    "print(\"GOLD_LATEST:\", GOLD_LATEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640bc228-428f-45a2-96bd-5910d508ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/25 20:46:53 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "26/01/25 20:46:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pools_s rows : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events_s rows: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------+----------+-----------------+--------------+--------------------------+\n",
      "|pool_id|event_time                |event_date|intervention_type|product_amount|updated_at                |\n",
      "+-------+--------------------------+----------+-----------------+--------------+--------------------------+\n",
      "|1      |2026-01-15 01:10:41.856293|2026-01-15|chlorine         |250.0         |2026-01-25 01:10:41.856293|\n",
      "|2      |2026-01-17 01:10:41.856293|2026-01-17|chlorine         |200.0         |2026-01-25 01:10:41.856293|\n",
      "|3      |2026-01-19 01:10:41.856293|2026-01-19|chlorine         |220.0         |2026-01-25 01:10:41.856293|\n",
      "|2      |2026-01-24 01:10:41.856293|2026-01-24|ph_correction    |120.0         |2026-01-25 01:10:41.856293|\n",
      "|5      |2026-01-24 01:10:41.856293|2026-01-24|ph_correction    |200.0         |2026-01-25 01:10:41.856293|\n",
      "|1      |2026-01-18 01:10:41.856293|2026-01-18|ph_correction    |150.0         |2026-01-25 01:10:41.856293|\n",
      "|5      |2026-01-18 01:10:41.856293|2026-01-18|chlorine         |400.0         |2026-01-25 01:10:41.856293|\n",
      "|2      |2026-01-21 01:10:41.856293|2026-01-21|refill           |1500.0        |2026-01-25 01:10:41.856293|\n",
      "|4      |2026-01-20 01:10:41.856293|2026-01-20|refill           |2500.0        |2026-01-25 01:10:41.856293|\n",
      "|1      |2026-01-25 19:07:21.820564|2026-01-25|chlorine         |180.0         |2026-01-25 19:07:21.820564|\n",
      "+-------+--------------------------+----------+-----------------+--------------+--------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "pools_s  = spark.read.format(\"delta\").load(POOLS_SILVER)\n",
    "events_s = spark.read.format(\"delta\").load(EVENTS_SILVER)\n",
    "\n",
    "print(\"pools_s rows :\", pools_s.count())\n",
    "print(\"events_s rows:\", events_s.count())\n",
    "\n",
    "events_s.select(\"pool_id\", \"event_time\", \"event_date\", \"intervention_type\", \"product_amount\", \"updated_at\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19de543d-d762-4a0a-afbb-612bee41171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "|pool_id|event_date|num_events|total_product_amount|n_chlorine|n_ph_correction|n_refill|n_filter_backwash|last_event_time           |calc_ts                   |\n",
      "+-------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "|1      |2026-01-25|2         |270.0               |1         |1              |0       |0                |2026-01-25 19:09:21.820564|2026-01-25 20:47:10.418557|\n",
      "|2      |2026-01-24|1         |120.0               |0         |1              |0       |0                |2026-01-24 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|5      |2026-01-24|1         |200.0               |0         |1              |0       |0                |2026-01-24 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|3      |2026-01-23|1         |0.0                 |0         |0              |0       |1                |2026-01-23 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|4      |2026-01-23|1         |180.0               |0         |1              |0       |0                |2026-01-23 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|1      |2026-01-22|1         |0.0                 |0         |0              |0       |1                |2026-01-22 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|5      |2026-01-22|1         |0.0                 |0         |0              |0       |1                |2026-01-22 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|2      |2026-01-21|1         |1500.0              |0         |0              |1       |0                |2026-01-21 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|4      |2026-01-20|1         |2500.0              |0         |0              |1       |0                |2026-01-20 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|3      |2026-01-19|1         |220.0               |1         |0              |0       |0                |2026-01-19 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|1      |2026-01-18|1         |150.0               |0         |1              |0       |0                |2026-01-18 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|5      |2026-01-18|1         |400.0               |1         |0              |0       |0                |2026-01-18 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|2      |2026-01-17|1         |200.0               |1         |0              |0       |0                |2026-01-17 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|4      |2026-01-16|1         |300.0               |1         |0              |0       |0                |2026-01-16 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "|1      |2026-01-15|1         |250.0               |1         |0              |0       |0                |2026-01-15 01:10:41.856293|2026-01-25 20:47:10.418557|\n",
      "+-------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "\n",
      "daily rows: 15\n"
     ]
    }
   ],
   "source": [
    "daily = (\n",
    "    events_s\n",
    "    .groupBy(\"pool_id\", \"event_date\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_events\"),\n",
    "        F.sum(F.when(F.col(\"product_amount\").isNotNull(), F.col(\"product_amount\")).otherwise(F.lit(0.0))).alias(\"total_product_amount\"),\n",
    "        F.sum(F.when(F.col(\"intervention_type\") == \"chlorine\", 1).otherwise(0)).alias(\"n_chlorine\"),\n",
    "        F.sum(F.when(F.col(\"intervention_type\") == \"ph_correction\", 1).otherwise(0)).alias(\"n_ph_correction\"),\n",
    "        F.sum(F.when(F.col(\"intervention_type\") == \"refill\", 1).otherwise(0)).alias(\"n_refill\"),\n",
    "        F.sum(F.when(F.col(\"intervention_type\") == \"filter_backwash\", 1).otherwise(0)).alias(\"n_filter_backwash\"),\n",
    "        F.max(\"event_time\").alias(\"last_event_time\"),\n",
    "        F.current_timestamp().alias(\"calc_ts\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "daily.orderBy(F.col(\"event_date\").desc(), F.col(\"pool_id\")).show(50, truncate=False)\n",
    "print(\"daily rows:\", daily.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2294765-8145-48fe-82f6-27aa88f05bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+---------------------+-------------+-------------+---------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "|pool_id|pool_name                      |location             |owner_type   |volume_liters|is_heated|event_date|num_events|total_product_amount|n_chlorine|n_ph_correction|n_refill|n_filter_backwash|last_event_time           |calc_ts                   |\n",
      "+-------+-------------------------------+---------------------+-------------+-------------+---------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "|1      |Piscina Casa Pueblo            |Valdeganga (Albacete)|private      |40000        |false    |2026-01-25|2         |270.0               |1         |1              |0       |0                |2026-01-25 19:09:21.820564|2026-01-25 20:47:12.010051|\n",
      "|2      |Piscina Villa Mila             |Valdeganga (Albacete)|private      |70000        |false    |2026-01-24|1         |120.0               |0         |1              |0       |0                |2026-01-24 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|5      |Piscina Polideportivo Municipal|Ciudad Real          |sports_center|80000        |true     |2026-01-24|1         |200.0               |0         |1              |0       |0                |2026-01-24 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|3      |Piscina Airbnb Rural           |Cuenca               |airbnb       |35000        |false    |2026-01-23|1         |0.0                 |0         |0              |0       |1                |2026-01-23 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|4      |Piscina Hotel Centro           |Madrid               |hotel        |60000        |true     |2026-01-23|1         |180.0               |0         |1              |0       |0                |2026-01-23 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|1      |Piscina Casa Pueblo            |Valdeganga (Albacete)|private      |40000        |false    |2026-01-22|1         |0.0                 |0         |0              |0       |1                |2026-01-22 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|5      |Piscina Polideportivo Municipal|Ciudad Real          |sports_center|80000        |true     |2026-01-22|1         |0.0                 |0         |0              |0       |1                |2026-01-22 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|2      |Piscina Villa Mila             |Valdeganga (Albacete)|private      |70000        |false    |2026-01-21|1         |1500.0              |0         |0              |1       |0                |2026-01-21 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|4      |Piscina Hotel Centro           |Madrid               |hotel        |60000        |true     |2026-01-20|1         |2500.0              |0         |0              |1       |0                |2026-01-20 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|3      |Piscina Airbnb Rural           |Cuenca               |airbnb       |35000        |false    |2026-01-19|1         |220.0               |1         |0              |0       |0                |2026-01-19 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|1      |Piscina Casa Pueblo            |Valdeganga (Albacete)|private      |40000        |false    |2026-01-18|1         |150.0               |0         |1              |0       |0                |2026-01-18 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|5      |Piscina Polideportivo Municipal|Ciudad Real          |sports_center|80000        |true     |2026-01-18|1         |400.0               |1         |0              |0       |0                |2026-01-18 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|2      |Piscina Villa Mila             |Valdeganga (Albacete)|private      |70000        |false    |2026-01-17|1         |200.0               |1         |0              |0       |0                |2026-01-17 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|4      |Piscina Hotel Centro           |Madrid               |hotel        |60000        |true     |2026-01-16|1         |300.0               |1         |0              |0       |0                |2026-01-16 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "|1      |Piscina Casa Pueblo            |Valdeganga (Albacete)|private      |40000        |false    |2026-01-15|1         |250.0               |1         |0              |0       |0                |2026-01-15 01:10:41.856293|2026-01-25 20:47:12.010051|\n",
      "+-------+-------------------------------+---------------------+-------------+-------------+---------+----------+----------+--------------------+----------+---------------+--------+-----------------+--------------------------+--------------------------+\n",
      "\n",
      "daily_enriched rows: 15\n"
     ]
    }
   ],
   "source": [
    "daily_enriched = (\n",
    "    daily.alias(\"d\")\n",
    "    .join(\n",
    "        pools_s.select(\"pool_id\", \"pool_name\", \"location\", \"owner_type\", \"volume_liters\", \"is_heated\").alias(\"p\"),\n",
    "        on=\"pool_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .select(\n",
    "        \"pool_id\", \"pool_name\", \"location\", \"owner_type\", \"volume_liters\", \"is_heated\",\n",
    "        \"event_date\", \"num_events\", \"total_product_amount\",\n",
    "        \"n_chlorine\", \"n_ph_correction\", \"n_refill\", \"n_filter_backwash\",\n",
    "        \"last_event_time\", \"calc_ts\"\n",
    "    )\n",
    ")\n",
    "\n",
    "daily_enriched.orderBy(F.col(\"event_date\").desc(), F.col(\"pool_id\")).show(50, truncate=False)\n",
    "print(\"daily_enriched rows:\", daily_enriched.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac65a6f2-98ca-41d7-8e91-a4ac6042f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD daily OK -> s3a://spark/medallion/gold/pool_daily_metrics\n"
     ]
    }
   ],
   "source": [
    "(daily_enriched.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .save(GOLD_DAILY)\n",
    ")\n",
    "\n",
    "print(\"GOLD daily OK ->\", GOLD_DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3054058-9c11-410f-97c7-36f7827166a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------------+-----------------+------------+--------------+---------------------------------------------------+--------------------------+----------+--------------------------+\n",
      "|pool_id|id  |event_time                |intervention_type|product_type|product_amount|notes                                              |updated_at                |event_date|calc_ts                   |\n",
      "+-------+----+--------------------------+-----------------+------------+--------------+---------------------------------------------------+--------------------------+----------+--------------------------+\n",
      "|1      |1003|2026-01-25 19:09:21.820564|ph_correction    |minus       |90.0          |Evento incremental de prueba 2                     |2026-01-25 19:07:21.820564|2026-01-25|2026-01-25 20:47:18.512766|\n",
      "|2      |6   |2026-01-24 01:10:41.856293|ph_correction    |plus        |120.0         |Corrección de pH por agua demasiado ácida          |2026-01-25 01:10:41.856293|2026-01-24|2026-01-25 20:47:18.512766|\n",
      "|3      |8   |2026-01-23 01:10:41.856293|filter_backwash  |NULL        |NULL          |Lavado de filtro tras varios días de alta ocupación|2026-01-25 01:10:41.856293|2026-01-23|2026-01-25 20:47:18.512766|\n",
      "|4      |11  |2026-01-23 01:10:41.856293|ph_correction    |minus       |180.0         |Ajuste de pH por uso intensivo                     |2026-01-25 01:10:41.856293|2026-01-23|2026-01-25 20:47:18.512766|\n",
      "|5      |14  |2026-01-24 01:10:41.856293|ph_correction    |minus       |200.0         |Corrección de pH tras sesión de aquagym            |2026-01-25 01:10:41.856293|2026-01-24|2026-01-25 20:47:18.512766|\n",
      "+-------+----+--------------------------+-----------------+------------+--------------+---------------------------------------------------+--------------------------+----------+--------------------------+\n",
      "\n",
      "latest_event rows: 5\n"
     ]
    }
   ],
   "source": [
    "w = Window.partitionBy(\"pool_id\").orderBy(F.col(\"event_time\").desc(), F.col(\"updated_at\").desc(), F.col(\"id\").desc())\n",
    "\n",
    "latest_event = (\n",
    "    events_s\n",
    "    .withColumn(\"rn\", F.row_number().over(w))\n",
    "    .filter(F.col(\"rn\") == 1)\n",
    "    .drop(\"rn\")\n",
    "    .withColumn(\"calc_ts\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "latest_event.orderBy(\"pool_id\").show(50, truncate=False)\n",
    "print(\"latest_event rows:\", latest_event.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b02a06-f108-424f-b31f-35d1ce6d910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD latest OK -> s3a://spark/medallion/gold/pool_latest_event\n"
     ]
    }
   ],
   "source": [
    "(latest_event.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .save(GOLD_LATEST)\n",
    ")\n",
    "\n",
    "print(\"GOLD latest OK ->\", GOLD_LATEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e22cf4-6f7b-48a7-a737-f6f44f39fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD daily rows : 15\n",
      "GOLD latest rows: 5\n",
      "[QA] dups daily (pool_id,event_date): 0\n",
      "[QA] dups latest (pool_id): 0\n",
      "[QA] daily pool_id sin pools_dim: 0\n",
      "Delta history GOLD_DAILY:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[version: bigint, timestamp: timestamp, userId: string, userName: string, operation: string, operationParameters: map<string,string>, job: struct<jobId:string,jobName:string,jobRunId:string,runId:string,jobOwnerId:string,triggerType:string>, notebook: struct<notebookId:string>, clusterId: string, readVersion: bigint, isolationLevel: string, isBlindAppend: boolean, operationMetrics: map<string,string>, userMetadata: string, engineInfo: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta history GOLD_LATEST:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[version: bigint, timestamp: timestamp, userId: string, userName: string, operation: string, operationParameters: map<string,string>, job: struct<jobId:string,jobName:string,jobRunId:string,runId:string,jobOwnerId:string,triggerType:string>, notebook: struct<notebookId:string>, clusterId: string, readVersion: bigint, isolationLevel: string, isBlindAppend: boolean, operationMetrics: map<string,string>, userMetadata: string, engineInfo: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04_gold OK\n"
     ]
    }
   ],
   "source": [
    "daily_g = spark.read.format(\"delta\").load(GOLD_DAILY)\n",
    "latest_g = spark.read.format(\"delta\").load(GOLD_LATEST)\n",
    "\n",
    "print(\"GOLD daily rows :\", daily_g.count())\n",
    "print(\"GOLD latest rows:\", latest_g.count())\n",
    "\n",
    "# Unicidad esperada\n",
    "dups_daily = daily_g.groupBy(\"pool_id\",\"event_date\").count().filter(\"count > 1\").count()\n",
    "dups_latest = latest_g.groupBy(\"pool_id\").count().filter(\"count > 1\").count()\n",
    "print(\"[QA] dups daily (pool_id,event_date):\", dups_daily)\n",
    "print(\"[QA] dups latest (pool_id):\", dups_latest)\n",
    "\n",
    "# Referencial (daily debe tener pool_id existente)\n",
    "missing_pool_daily = (daily_g.select(\"pool_id\").distinct()\n",
    "    .join(pools_s.select(\"pool_id\").distinct(), on=\"pool_id\", how=\"left_anti\")\n",
    "    .count()\n",
    ")\n",
    "print(\"[QA] daily pool_id sin pools_dim:\", missing_pool_daily)\n",
    "\n",
    "print(\"Delta history GOLD_DAILY:\")\n",
    "display(DeltaTable.forPath(spark, GOLD_DAILY).history(10))\n",
    "\n",
    "print(\"Delta history GOLD_LATEST:\")\n",
    "display(DeltaTable.forPath(spark, GOLD_LATEST).history(10))\n",
    "\n",
    "print(\"04_gold OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e253329-f1aa-4231-a368-302008af7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61e90f-d7b1-4365-92de-53c87c0328fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
